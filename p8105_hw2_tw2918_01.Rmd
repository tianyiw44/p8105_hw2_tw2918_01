---
title: "p8105_hw2_tw2918_01"
output: github_document
date: "2023-09-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r load_libraries}
library(tidyverse)
library(readxl)
```

# Probelm 1
## 1. Clean the data in pols-month.csv.
### (1) Use `separate()` to break up the variable `mon` into integer variables `year`, `month`, and `day`

### (2)  replace month number with month abbreviation

### (3) create a `president` variable taking values `gop` and `dem`, and remove `prez_dem` and `prez_gop`

### (4) remove `day` variable 

```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )
```

```{r}
pols_month_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv")|>
  janitor::clean_names()|>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE)|>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -month_abb, -day, -starts_with("prez"))
```
 
## 2. clean the data in snp.csv using a similar process to the above
### (1) Use `separate()` to break up the variable `date` into integer variables `year`, `month`, and `day`
### (2)  replace month number with month abbreviation and remove `day` varialbe
### (3)  arrange according to year and month

```{r}
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv")|>
  janitor::clean_names()|>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month)|>
  mutate(month = month.name[as.numeric(month)])|>
  select(year, month,close)
```

## 3. tidy the unemployment data

```{r}
unemp_df = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv")|>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

## 4. Join the datasets by merging `snp` into `pols`, and merging `unemployment` into the result

```{r merge_538}
data_538 = 
  left_join(pols_month_df, snp_df) |>
  left_join(x = _, y = unemp_df)

str(data_538)
```

# Probelm 2 
## 1. Read and Clearn Mr. Trash Wheel Dataset

```{r}
mr_trashwheel_df = 
  read_excel( "./202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Mr. Trash Wheel",
    range = "A2:N586"
    ) |>
  janitor::clean_names()|>
  mutate(
    homes_powered_new = weight_tons*500/30,
    trash_wheel="mr_trash_wheel",
    year=as.numeric(year)
    ) |>
  select(trash_wheel, everything(), -homes_powered)
```

## 2. Use a similar process to import, clean, and organize the data for Professor Trash Wheel

```{r}
pf_trashwheel_df = 
  read_excel( "./202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Professor Trash Wheel",
    range = "A2:M108"
    ) |>
  janitor::clean_names()|>
  mutate(
    homes_powered_new = weight_tons*500/30,
    trash_wheel = "professor_trash_wheel") |>
  select(trash_wheel, everything(), -homes_powered)
```

## 3. Use a similar process to import, clean, and organize the data for Gwynnda Trash Wheel

```{r}
gwy_trashwheel_df=
  read_excel( "./202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Gwynnda Trash Wheel",
    range = "A2:L157"
    ) |>
  janitor::clean_names()|>
  mutate(
    homes_powered_new = weight_tons*500/30,
    trash_wheel = "gwynnda_trash_wheel") |>
  select(trash_wheel, everything(), -homes_powered)
```

## 4. Combine Datasets 

First, changed the above code to state which trash wheel is which
Second, unify variable type. fixed the column type of year variable in Mr. Trash Wheel Dataset.
Third combine datasets using `full_join` sine we want to keep all values in three datasets. 

```{r}
mr_pf_trashwheel_df = 
  full_join(mr_trashwheel_df, pf_trashwheel_df)

trashwheel_df = 
  full_join(mr_pf_trashwheel_df, gwy_trashwheel_df)
```

## 5. Write a paragraph about the data
The `trashwheel_df` dataset contains data from all three dataset, Mr.Trash Wheel, Professor Trash Wheel and Gwynnda Trash Wheel. It contains `r nrow(trashwheel_df)` observations of trash collected. The data contains `r ncol(trashwheel_df)` variables. The variables include `month` `year` and `date` of the collected `dumspter`, weight of the `dumspter`, measured in tons (`weight_ton`), volume of the `dumspter`, measured in cubic yards (`volume_cubic_yards`) and the type of trash collected, such as `plastic_bottle`, `polysyrene`, `ciagrette_butt`, `glass_bottle`,`grocery_bags`, `chip_bags`, `sports_ball` and `plastic_bags`.There are missing values because each trash wheel collects different types of trash and the combination creates missing values for the type of trash they don't collect. The last variable `homes_powered_new` is number of homes powered by the collected trash, calculated using`weight_ton` times 500 kilowatts of electricity creates per ton, then divided by 30 kilowatts needed per home.

For available data, the total weight of trash collected by Professor Trash Wheel is `r sum(pull(pf_trashwheel_df, weight_tons))`. The total number of cigarette butts collected by Gwynnda in July of 2021 is `r sum(pull(filter(gwy_trashwheel_df, month == "July" & year == "2021"), cigarette_butts))`. 

# Probelm 3
## 1. Import, clean, and tidy the dataset of baseline demographics

```{r}
baseline_df = 
  read_csv("./data_mci/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names()|>
  mutate(
    sex = ifelse(sex == 0, "female", "male"),
    apoe4 = ifelse(apoe4 == 0, "non_carrier", "carrier"),
    age_at_onset = replace(age_at_onset, age_at_onset == ".", NA),
  ) |>
  filter(is.na(age_at_onset)|age_at_onset>current_age)
```

## 2. Discuss important steps in the import process and relevant features of the dataset

* when using `read_csv` to import data, I used `skip=1` to skip the first row. The first row is descriptions of the variables
* used `janitor::clean_names` to tidy variable names
* used the `mutat`e` function to replace  `sex` value from `0`,`1` to `female` and `male`
* used the `mutate` function to replace `apoe4` value from `0`,`1` to `non_carrier` and `carrier`
* used `mutate` function to replace missing value of `age_at_onset` from `.` to `NA`
* used `filter` function to select and exact only the rows that meet the stated inclusion criteria, no MCI at baseline, which is either a missing value of `age_at_onset` or when `age_at_onset` is larger than `current_age` at baseline
* There were `r nrow(baseline_df)` participants recruited
* Of those recruited, `r sum(!is.na(pull(baseline_df, age_at_onset)))` developed MCI
* The average baseline age is `r mean(baseline_df$current_age)`
* `r nrow(filter(baseline_df, sex=="female"& apoe4=="carrier")) / nrow(filter(baseline_df, sex== "female")) * 100`% of women in the study are APOE4 carriers

## 3.  Import, clean, and tidy the dataset of longitudinally observed biomarker values

```{r}
long_biomaker_df = 
  read_csv("./data_mci/mci_amyloid.csv", skip=1) |>
  janitor::clean_names()|>
  mutate(baseline = replace(baseline, baseline == "Na", NA))|>
  rename(id = study_id)
```

## 4. Discuss important steps in the import process and relevant features of the dataset

* when using `read_csv` to import data, I used `skip=1` to skip the first row. The first row is descriptions of the variables.
* used `janitor::clean_names` to tidy variable names
* used `mutate` to replace `basline` value "Na" to `NA`
* used `rename` function to rename study_id to id to make it consistant with `baseline_df`
* There are `r nrow(long_biomaker_df)` participants in this dataset
* There are `r ncol(long_biomaker_df)`variable including the `baseline` time in years when biomaker amyloid is measured, the second visit (`time_2`), fourth visit (`time_4`), sixth visit (`time_6`) and Eightth visit (`time_8`) when it is measured.

## 5. Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings

There are `r nrow(baseline_df)` observations in the baseline dataset, and  `r nrow(long_biomaker_df)` in the amyloid dateset. The amloid dataset has `r nrow(long_biomaker_df) - nrow(baseline_df)` more observations than the baseline. Therefore, there must be some participants that appear in only the the biomaker dataset. 
 
## 6. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained and briefly describe the resulting dataset

```{r}
mci_demographic_biomaker_df = 
  inner_join(baseline_df, long_biomaker_df)
```

* used `inner_join` to only keep participants who appear in both datasets
* the resuiting dataset `mci_demographic_biomaker_df` contains `r nrow(mci_demographic_biomaker_df)`observations and`r ncol(mci_demographic_biomaker_df)` variables
* The variables contains baseline character of the participants including baseline age (`current_age`), `sex`, years of `education`, wheter they carry `apoe4` and mci `age_at_onset`. It also contains biomaker amyloid measurement time at `baseline`, second, forth, sixth and eighth time visit, named as `baseline`, `time_2`, `time_4`, `time_6` and `time_8`. 

## 7. export the result as a CSV to your data directory.

```{r}
write.csv(mci_demographic_biomaker_df, "./mic_demographic_biomaker.csv")
```

